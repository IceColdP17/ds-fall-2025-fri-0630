{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Very First Machine Learning (ML) Model: Logistic Regression\n",
    "\n",
    "Dataset: [College Student Placement Factors Dataset](https://www.kaggle.com/datasets/sahilislam007/college-student-placement-factors-dataset) (`data/college_student_placement_dataset.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries.\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "It is a good programming practice to use constants to avoid repetition errors and to save yourself the effort of retyping the expression by _centralizing_ semantically identical values.\n",
    "\n",
    "`DATASET_PATH` identifies the path to the dataset being loaded and operated on. `RANDOM_STATE` makes otherwise random operations reproducible run after run. Keep whatever value you set it to unless you want slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/college_student_placement_dataset.csv\"\n",
    "RANDOM_STATE = 45  # DO NOT CHANGE THIS RANDOM STATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Inspection\n",
    "\n",
    "See what the raw file looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 lines of theraw contents of the file first.\n",
    "\n",
    "with open(DATASET_PATH, \"r\") as file:\n",
    "    for line_number in range(5):\n",
    "        if line := file.readline():\n",
    "            print(line)\n",
    "        else:\n",
    "            break  # Stop; there are less than 5 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Load\n",
    "\n",
    "Load the data. This is not the final form of the data which will be used, but it‚Äôs a `DataFrame` for further inspection so we can decide what to do with it next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH, index_col=\"College_ID\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values Check\n",
    "Inspect which varibles may be good / not good for using as features based on null values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which columns have null values.\n",
    "df.isnull().sum().to_frame(\"nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Rows Check\n",
    "If so, remove the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if our data has any duplicate rows.\n",
    "sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many clean‚Ä¶ üòê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Categories\n",
    "\n",
    "What are the categories for the categorial-looking (i.e., non-numeric) columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_column_name in df.select_dtypes(exclude=np.number):\n",
    "    print(f\"{categorical_column_name}: {df[categorical_column_name].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Non-numeric columns containing `'Yes'` and `'No'` do not work with logistic regression. Binary categories can be converted an integral type (`int`) with a value of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Internship_Experience\"] = df[\"Internship_Experience\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df[\"Placement\"] = df[\"Placement\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùî When should you use this versus using `pd.get_dummies`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with `sns.pairplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sns.pariplot to visualize.\n",
    "sns.pairplot(df, hue=\"Placement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "\n",
    "Choose the columns corresponding to the features _IQ_ and _internship experience_ to be your `X`. Target _placement_ as your `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X to the desired features.\n",
    "X = df[[\"IQ\", \"Internship_Experience\"]]\n",
    "\n",
    "# Set y to be our target variable.\n",
    "y = df[\"Placement\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to Testing and Training Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into testing and training pairs.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Print the length and width of our testing data.\n",
    "print(\"X_train: %d rows, %d columns\" % X_train.shape)\n",
    "print(\"X_test: %d rows, %d columns\" % X_test.shape)\n",
    "print(\"y_train: %d rows, 1 column\" % y_train.shape)\n",
    "print(\"y_test: %d rows, 1 column\" % y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train your model\n",
    "\n",
    "Initialize an empty Logistic Regression model, and then fit your model to your training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize our logistic regressionmodel.\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Make predictions with your test data and save the predictions as `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions of your test data and save them as `y_pred`.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and print the accuracy, precision, recall, and F1 scores of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate and print the accuracy, precision, recall, and F1 scores of your model.\n",
    "\n",
    "print(\"Accuracy Score: %f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision Score: %f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall Score: %f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: %f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a confusion matrix of your predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plot a confusion matrix of your predicted results.\n",
    "cm = confusion_matrix(y_test, y_pred).round(2)\n",
    "ax = sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt=\"g\")\n",
    "plt.title(\"Confusion Matrix of Placed Students\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many true positives and true negatives did your model get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many true positives and true negatives did your model get?\n",
    "true_negatives, false_positives, false_negatives, true_positives = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negatives: %d\" % true_negatives)\n",
    "print(\"True Positives: %d\" % true_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such awful üòû"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Most Important Feature\n",
    " \n",
    "Use `statsmodel` to create a summary report. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the independent variables.\n",
    "\n",
    "\n",
    "# Fit the model.\n",
    "\n",
    "\n",
    "# Print the summary and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: Use your brain and make a better model (as in better scores).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new X variable, and reuse the same y variable from before.\n",
    "\n",
    "\n",
    "# Split our data into testing and training. Remember to use the same random state as you used before\n",
    "\n",
    "\n",
    "# Initalize our model.\n",
    "\n",
    "\n",
    "# Fit-train our model using our training data.\n",
    "\n",
    "\n",
    "# Make new predicitions using our testing data.\n",
    "\n",
    "\n",
    "# Print each of our scores to inspect performance.\n",
    "\n",
    "\n",
    "# Plot the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
